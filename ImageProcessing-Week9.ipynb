{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron(object):\n",
    "\n",
    "    def __init__(self,input_size,lr=1,epochs=10):\n",
    "        self.W = np.zeros(input_size+1)\n",
    "        # add one for bias\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "           \n",
    "    def activation_fn(self,x):\n",
    "        return 1 if x >= 0 else 0\n",
    "    \n",
    "    def predict(self,x):\n",
    "        x = np.insert(x,0,1)\n",
    "        z = self.W.T.dot(x)\n",
    "        a = self.activation_fn(z)\n",
    "        return a\n",
    "    \n",
    "    def fit(self,X,d):\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(d.shape[0]):\n",
    "                y = self.predict(X[i])\n",
    "                e = d[i] - y\n",
    "                self.W = self.W + self.lr * e * np.insert(X[i],0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "        [0,0],\n",
    "        [0,1],\n",
    "        [1,0],\n",
    "        [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(input_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron.fit(X,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.,  2.,  1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.  2.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(perceptron.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron.predict(np.asarray([1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp = Perceptron(5)\n",
    "x = np.asarray([1,1,0,0,0])\n",
    "mp.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.activation_fn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Perceptron>\n",
    "\n",
    "    Yapay sinir ağı modelinin en küçük parçası olan perceptron'da y = W.x+b lineer fonksiyonuyla tanımlanır.  \n",
    "x girdi değerimiz, örneğin kedi resimlerini tanıyorsak kedi resmine ait matrisi, y ise bu resmin kediye ne kadar benzediğine dair skoru verir. Parametrelerimiz olan W ağırlık ve b bias değerlerini bu çıktı skorunu iyileştirmek için kullanılır. Bu anlamda çok katmanlı yapay sinir ağlarında ya da derin öğrenme de yaptığımız temel şey modelimiz için en iyi skoru verecek w ve b parametre değerlerini hesaplamaktır.\n",
    "    \n",
    "  Derin bir sinir ağı oluşturmak için temel bir yapı taşı olarak hizmet eder. Temel olarak, veri setini tek bir satır kullanarak iki kategoride sınıflandırabiliyorsanız, bu problem doğrusal olarak ayrılabilir olarak adlandırılır. Doğrusal olmayan ayrılabilir problemler de vardır. Bu problemlerde veri seti çoklu sınıflar içerir ve bunları kendi sınıflarına ayırmak için doğrusal olmayan bir çizgi gerektirir.\n",
    "Doğrusal olarak ayrılabilir bir problemin grafiğini çizerek ve doğrusal olmayan problemli veri setini çizerek, ikisi arasındaki fark şu şekildedir: \n",
    "\n",
    "        1) Perceptron class tanımında var olan fonksiyonları kısaca tanıtınız.\n",
    "\n",
    "<init fonksiyonu>\n",
    "Bir programı çağırdığınızda değişkenler başlatılmaz. Yani, bu kodu kullanarak programındaki tüm değişkenleri açıkça başlatırız. Bununla beraber bir perceptron yani Algılayıcı oluşturmuş oluruz. Weight yani “ağırlık” vektörünü oluşturmamız gerekir bu işlem için bir kullanıcıdan girdi alırız. W.x çarpımından oluşturulan lineer doğruyu öteleyerek daha iyi çözecek konuma getirmek için bias değerini ekliyoruz. Dışarıdan değişitirilebilir olarak 2 parametre ekledik. Öğrenme oranını ve devir sayısı değiştirilebilirlerdir.\n",
    "\n",
    "<activation_fn fonksiyonu>\n",
    "Çıktılar aktivasyon fonksiyonlarıyla non-lineer hale getirilebilmektedir. Aktivasyon fonksiyonumuz eşik değeri belirledikten sonra,\n",
    "eğer girdi 0 dan büyük veya eşitse  1 , değilse 0 döndürüyoruz. \n",
    "Böylelikle gelen girdi için çıkacak çıktıyı bulmuş oluyoruz.\n",
    "\n",
    "<predict fonksiyonu>\n",
    "Bu fonksiyon Tahmin fonksiyonudur. Perceptron yardımıyla girdiyi çalıştırıyoruz. Bunun sonucunda çıktı döndürmesi için yazılması gereken ve sonucunun bize verildiği fonksiyondur. giriş vektörüne ekledik. İç çarpımı hesapladık ve aktivasyon fonksiyonunu kullandık. Makineye bunu öğrettikten sonra sonuç tahmin edilir.\n",
    "\n",
    "<fit fonksiyonu>\n",
    "Makineyi eğittiğimiz, öğrettiğimiz fonksiyondur.\n",
    "\n",
    "        2) XOR için verileri değiştirip çalışmasınızı gözlemleyiniz.\n",
    "\n",
    "    Tek katmanlı perceptron’un birçok Bool fonksiyonunu öğrenebildiği gösterildi. Fakat perceptron’un XOR fonksiyonunu öğrenemeyeceğini gösterdi. \n",
    "Bir perceptrona mazur bırakıp outputunu alıprız. Bir başka perceptrona göndeririz. Önce 2 ye ayırıp sorunlu olan tarafı tekrar bir perceptrona maruz bırakıp tamamen çözüm sağlayabilriz. 2 perceptrona maruz bırakılıan sorun çözüldüğünde artık MLP ortaya çıkmış olur. Yani ihtiyaç olduğu kadar perceptron uygulanarak sorun çözülebilir.\n",
    "\n",
    "        3) Bu class ile dersimize kayıtlı 40 öğrenci için imza tanıması yapılırsa X ve d değerlerini ne olur, predict fonksiyonu nasıl kullanılır açıklayınız.\n",
    "\n",
    "    2 input değerlerimiz vardır. X değerleri input ve d değerleri ise output'u temsil etmektedir. Bunlar Yükseklik - Genişlik değerleridir. Bunun sonucunda X değeri 40 adet dizi tutar bunlar imzaları tutacaktır. d değeri ise 40 elemanlıdır. Bu değerlerin her biri X dizisinde bulunan imzanın hangi öğrenciye ait olduğunu gösterir. Her bir sütununda bir kişiye ait imza resmi olmak üzere (100*100*3,40) lık matrix bizim verimiz olacaktır. \n",
    "Sıradaki işlem predict fonsiyonunu kullanıp imzanın kime ait olduğunu bulmaktır. Bunun için predict fonsiyonua input olarak öğrenci imzası verilir. Predict fonksiyonu sonuç olarak imzanın hangi öğrenciye ait olduğunu çıktı olarak verir. \n",
    "\n",
    "        4)Bu modelin hatası nasıl elde edilir, kendi çözümünüzü/ yorumunuzu yazınız.\n",
    "\n",
    "    Yaptığım araştırmlar sonucunda birkaç hata çözümlemesi ile karşılaştım.\n",
    "** TensorFlow, ardışık yinelemelerde kaybı en aza indirmek için her bir değişkeni (ağırlık ve sapma) yavaşça değiştiren optimize ediciler sağlar. En basit iyileştirici, hata gidericidir. \n",
    "** Aynı zamanda hatayı hesaplamak için çapraz entropi(cross entropy) kullanılabilir.  Zamanın her birinde, maliyet hesaplanır ve bu maliyete bağlı olarak optimizatör, hatayı en aza indirmek için ağırlık ve önyargı değişkenlerini değiştirir.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
